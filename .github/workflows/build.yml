name: Build Slim PyArrow

on:
  push:
    branches: [main]
    tags: ['v*']
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      arrow_version:
        description: 'Arrow version to build'
        required: false
        default: '22.0.0'

env:
  ARROW_VERSION: ${{ github.event.inputs.arrow_version || '22.0.0' }}

jobs:
  build:
    runs-on: ${{ matrix.runner }}
    strategy:
      fail-fast: false
      matrix:
        include:
          # Linux AMD64
          - arch: amd64
            runner: ubuntu-latest
            python: '3.12'
            manylinux: manylinux_2_28_x86_64
            platform_tag: x86_64
          - arch: amd64
            runner: ubuntu-latest
            python: '3.13'
            manylinux: manylinux_2_28_x86_64
            platform_tag: x86_64
          # Linux ARM64 (native runner - faster than QEMU)
          - arch: arm64
            runner: ubuntu-24.04-arm
            python: '3.12'
            manylinux: manylinux_2_28_aarch64
            platform_tag: aarch64
          - arch: arm64
            runner: ubuntu-24.04-arm
            python: '3.13'
            manylinux: manylinux_2_28_aarch64
            platform_tag: aarch64

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # Note: QEMU not needed - using native ARM64 runners (ubuntu-24.04-arm)

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Get Python version tag
        id: python
        run: |
          PYTHON_TAG="cp$(echo ${{ matrix.python }} | tr -d '.')"
          echo "tag=${PYTHON_TAG}-${PYTHON_TAG}" >> $GITHUB_OUTPUT
          echo "Python tag: ${PYTHON_TAG}"

      - name: Create wheelhouse directory
        run: mkdir -p wheelhouse

      - name: Build PyArrow wheel
        run: |
          docker run --rm \
            --platform linux/${{ matrix.arch }} \
            -v ${{ github.workspace }}/wheelhouse:/wheelhouse \
            -e ARROW_VERSION=${{ env.ARROW_VERSION }} \
            -e PYTHON_TAG=${{ steps.python.outputs.tag }} \
            quay.io/pypa/${{ matrix.manylinux }} \
            /bin/bash -c '
              set -ex
              
              # Install build tools (manylinux_2_28 uses dnf)
              dnf install -y cmake ninja-build git wget
              
              # Set paths
              export ARROW_HOME=/opt/arrow
              export PATH="${ARROW_HOME}/bin:${PATH}"
              export LD_LIBRARY_PATH="${ARROW_HOME}/lib:${ARROW_HOME}/lib64"
              
              # Fix CMake compatibility with bundled dependencies
              export CMAKE_POLICY_VERSION_MINIMUM=3.5
              
              # Clone Arrow
              cd /tmp
              git clone --depth 1 --branch apache-arrow-${ARROW_VERSION} \
                https://github.com/apache/arrow.git
              
              # Pre-download Thrift from Apache Archive (dlcdn.apache.org often returns 404)
              mkdir -p /tmp/arrow/cpp/build/thrift_ep-prefix/src
              cd /tmp/arrow/cpp/build/thrift_ep-prefix/src
              wget -q https://archive.apache.org/dist/thrift/0.20.0/thrift-0.20.0.tar.gz || \
                wget -q https://github.com/apache/thrift/archive/refs/tags/v0.20.0.tar.gz -O thrift-0.20.0.tar.gz
              
              # Build Arrow C++
              mkdir -p /tmp/arrow/cpp/build
              cd /tmp/arrow/cpp/build
              cmake .. \
                -GNinja \
                -DCMAKE_BUILD_TYPE=Release \
                -DCMAKE_INSTALL_PREFIX=${ARROW_HOME} \
                -DCMAKE_INSTALL_LIBDIR=lib \
                -DCMAKE_POLICY_VERSION_MINIMUM=3.5 \
                -DARROW_PARQUET=ON \
                -DARROW_FILESYSTEM=ON \
                -DARROW_COMPUTE=ON \
                -DARROW_IPC=ON \
                -DARROW_DATASET=ON \
                -DARROW_CSV=ON \
                -DARROW_JSON=ON \
                -DARROW_WITH_SNAPPY=ON \
                -DARROW_WITH_ZSTD=ON \
                -DARROW_WITH_LZ4=ON \
                -DARROW_WITH_ZLIB=ON \
                -DARROW_S3=OFF \
                -DARROW_GCS=OFF \
                -DARROW_AZURE=OFF \
                -DARROW_HDFS=OFF \
                -DARROW_FLIGHT=OFF \
                -DARROW_FLIGHT_SQL=OFF \
                -DARROW_GANDIVA=OFF \
                -DARROW_ORC=OFF \
                -DARROW_CUDA=OFF \
                -DARROW_SUBSTRAIT=OFF \
                -DARROW_ACERO=OFF \
                -DARROW_BUILD_TESTS=OFF \
                -DARROW_BUILD_BENCHMARKS=OFF \
                -DARROW_BUILD_UTILITIES=OFF \
                -DARROW_DEPENDENCY_SOURCE=BUNDLED \
                -DARROW_THRIFT_URL="https://archive.apache.org/dist/thrift/0.20.0/thrift-0.20.0.tar.gz"
              ninja install
              
              # Build PyArrow
              PYTHON_BIN=/opt/python/${PYTHON_TAG}/bin/python
              ${PYTHON_BIN} -m pip install cython numpy setuptools wheel setuptools_scm
              
              cd /tmp/arrow/python
              export PYARROW_WITH_PARQUET=1
              export PYARROW_WITH_DATASET=1
              export PYARROW_WITH_S3=0
              export PYARROW_WITH_GCS=0
              export PYARROW_WITH_HDFS=0
              export PYARROW_WITH_FLIGHT=0
              export PYARROW_WITH_GANDIVA=0
              export PYARROW_WITH_ORC=0
              export PYARROW_WITH_CUDA=0
              export PYARROW_WITH_SUBSTRAIT=0
              export PYARROW_WITH_ACERO=0
              export PYARROW_BUNDLE_ARROW_CPP=1
              
              ${PYTHON_BIN} setup.py build_ext --build-type=release bdist_wheel
              
              # Repair wheel
              auditwheel repair dist/*.whl -w /wheelhouse
            '

      - name: List built wheels
        run: |
          echo "=== Built wheels ==="
          ls -lh wheelhouse/
          echo ""
          echo "=== Wheel sizes ==="
          for wheel in wheelhouse/*.whl; do
            SIZE_BYTES=$(stat -c%s "$wheel")
            SIZE_MB=$((SIZE_BYTES / 1024 / 1024))
            echo "$(basename $wheel): ${SIZE_MB} MB"
          done

      - name: Upload wheel artifact
        uses: actions/upload-artifact@v4
        with:
          name: pyarrow-slim-${{ matrix.arch }}-py${{ matrix.python }}
          path: wheelhouse/*.whl
          retention-days: 30

  # Combine all wheels into a single artifact
  combine-wheels:
    needs: [build, build-macos]
    runs-on: ubuntu-latest
    steps:
      - name: Download all wheel artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: pyarrow-slim-*
          path: all-wheels
          merge-multiple: true

      - name: List all wheels
        run: |
          echo "=== All built wheels ==="
          ls -lh all-wheels/
          echo ""
          echo "=== Total size ==="
          du -sh all-wheels/

      - name: Upload combined artifact
        uses: actions/upload-artifact@v4
        with:
          name: pyarrow-slim-all-wheels
          path: all-wheels/*.whl
          retention-days: 90

  # Create GitHub Release with wheels
  release:
    needs: combine-wheels
    if: startsWith(github.ref, 'refs/tags/v')
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Download all wheels
        uses: actions/download-artifact@v4
        with:
          name: pyarrow-slim-all-wheels
          path: wheels

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          files: wheels/*.whl
          generate_release_notes: true
          body: |
            ## Slim PyArrow Wheels for PyIceberg
            
            These wheels contain a minimal PyArrow build optimized for PyIceberg with Cloudflare R2 Data Catalog.
            
            ### Enabled Features
            - Parquet file support
            - Filesystem abstraction
            - Compute kernels
            - Dataset API
            - Compression: Snappy, ZSTD, LZ4, ZLIB
            
            ### Disabled Features (for smaller size)
            - S3/GCS/Azure native filesystem (use `s3fs` instead)
            - HDFS, Flight, Gandiva, ORC, CUDA, Substrait, Acero
            
            ### Installation
            ```bash
            pip install pyarrow --no-index --find-links https://github.com/${{ github.repository }}/releases/download/${{ github.ref_name }}/
            ```
            
            Or install a specific wheel:
            ```bash
            pip install https://github.com/${{ github.repository }}/releases/download/${{ github.ref_name }}/pyarrow-18.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
            ```

  # Build macOS ARM64 wheels (native build, no Docker)
  build-macos:
    runs-on: macos-15
    strategy:
      fail-fast: false
      matrix:
        python: ['3.12', '3.13']

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}

      - name: Install build dependencies
        run: |
          brew install cmake ninja

      - name: Get Python version tag
        id: python
        run: |
          PYTHON_TAG="cp$(echo ${{ matrix.python }} | tr -d '.')"
          echo "tag=${PYTHON_TAG}" >> $GITHUB_OUTPUT
          echo "Python tag: ${PYTHON_TAG}"

      - name: Create directories
        run: |
          mkdir -p wheelhouse
          mkdir -p $HOME/arrow-install

      - name: Clone Arrow
        run: |
          cd /tmp
          git clone --depth 1 --branch apache-arrow-${{ env.ARROW_VERSION }} \
            https://github.com/apache/arrow.git

      - name: Build Arrow C++
        run: |
          export ARROW_HOME=$HOME/arrow-install
          
          mkdir -p /tmp/arrow/cpp/build
          cd /tmp/arrow/cpp/build
          
          cmake .. \
            -GNinja \
            -DCMAKE_BUILD_TYPE=Release \
            -DCMAKE_INSTALL_PREFIX=${ARROW_HOME} \
            -DCMAKE_INSTALL_LIBDIR=lib \
            -DCMAKE_OSX_ARCHITECTURES=arm64 \
            -DARROW_PARQUET=ON \
            -DARROW_FILESYSTEM=ON \
            -DARROW_COMPUTE=ON \
            -DARROW_IPC=ON \
            -DARROW_DATASET=ON \
            -DARROW_CSV=ON \
            -DARROW_JSON=ON \
            -DARROW_WITH_SNAPPY=ON \
            -DARROW_WITH_ZSTD=ON \
            -DARROW_WITH_LZ4=ON \
            -DARROW_WITH_ZLIB=ON \
            -DARROW_S3=OFF \
            -DARROW_GCS=OFF \
            -DARROW_AZURE=OFF \
            -DARROW_HDFS=OFF \
            -DARROW_FLIGHT=OFF \
            -DARROW_FLIGHT_SQL=OFF \
            -DARROW_GANDIVA=OFF \
            -DARROW_ORC=OFF \
            -DARROW_CUDA=OFF \
            -DARROW_SUBSTRAIT=OFF \
            -DARROW_ACERO=OFF \
            -DARROW_BUILD_TESTS=OFF \
            -DARROW_BUILD_BENCHMARKS=OFF \
            -DARROW_BUILD_UTILITIES=OFF \
            -DARROW_DEPENDENCY_SOURCE=BUNDLED
          
          ninja install

      - name: Build PyArrow wheel
        run: |
          export ARROW_HOME=$HOME/arrow-install
          export PATH="${ARROW_HOME}/bin:${PATH}"
          export DYLD_LIBRARY_PATH="${ARROW_HOME}/lib"
          
          # Force ARM64-only build (not universal2)
          export _PYTHON_HOST_PLATFORM="macosx-11.0-arm64"
          export ARCHFLAGS="-arch arm64"
          
          python -m pip install --upgrade pip
          python -m pip install cython numpy setuptools wheel setuptools_scm delocate
          
          cd /tmp/arrow/python
          
          export PYARROW_WITH_PARQUET=1
          export PYARROW_WITH_DATASET=1
          export PYARROW_WITH_S3=0
          export PYARROW_WITH_GCS=0
          export PYARROW_WITH_HDFS=0
          export PYARROW_WITH_FLIGHT=0
          export PYARROW_WITH_GANDIVA=0
          export PYARROW_WITH_ORC=0
          export PYARROW_WITH_CUDA=0
          export PYARROW_WITH_SUBSTRAIT=0
          export PYARROW_WITH_ACERO=0
          export PYARROW_BUNDLE_ARROW_CPP=1
          
          python setup.py build_ext --build-type=release bdist_wheel
          
          # Repair wheel with delocate (macOS equivalent of auditwheel)
          delocate-wheel -v -w ${{ github.workspace }}/wheelhouse dist/*.whl

      - name: List built wheels
        run: |
          echo "=== Built wheels ==="
          ls -lh wheelhouse/
          echo ""
          echo "=== Wheel sizes ==="
          for wheel in wheelhouse/*.whl; do
            SIZE_BYTES=$(stat -f%z "$wheel")
            SIZE_MB=$((SIZE_BYTES / 1024 / 1024))
            echo "$(basename $wheel): ${SIZE_MB} MB"
          done

      - name: Upload wheel artifact
        uses: actions/upload-artifact@v4
        with:
          name: pyarrow-slim-macos-arm64-py${{ matrix.python }}
          path: wheelhouse/*.whl
          retention-days: 30

  # Test the built wheels
  test:
    needs: [build, build-macos]
    runs-on: ${{ matrix.runner }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - arch: amd64
            runner: ubuntu-latest
            platform_tag: x86_64
          # ARM64 test with native runner
          - arch: arm64
            runner: ubuntu-24.04-arm
            platform_tag: aarch64
          # macOS ARM64 test
          - arch: macos-arm64
            runner: macos-15
            platform_tag: arm64

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Download wheels
        uses: actions/download-artifact@v4
        with:
          name: pyarrow-slim-all-wheels
          path: wheels

      - name: List available wheels
        run: ls -la wheels/

      - name: Install slim PyArrow
        run: |
          # Find the correct wheel for this platform
          WHEEL=$(ls wheels/*cp312*${{ matrix.platform_tag }}*.whl | head -1)
          echo "Installing: ${WHEEL}"
          pip install "${WHEEL}"

      - name: Test PyArrow imports
        run: |
          python -c "
          import pyarrow
          print(f'PyArrow version: {pyarrow.__version__}')
          
          import pyarrow.parquet as pq
          print('✓ pyarrow.parquet imported')
          
          import pyarrow.compute as pc
          print('✓ pyarrow.compute imported')
          
          import pyarrow.dataset as ds
          print('✓ pyarrow.dataset imported')
          
          import pyarrow.fs as pafs
          print('✓ pyarrow.fs imported')
          
          # Verify S3 is NOT available (as expected)
          try:
              from pyarrow.fs import S3FileSystem
              print('⚠ S3FileSystem available (unexpected)')
          except ImportError:
              print('✓ S3FileSystem not available (expected - use s3fs)')
          
          print('')
          print('All imports successful!')
          "

      - name: Test PyIceberg compatibility
        run: |
          pip install "pyiceberg[s3fs]"
          python -c "
          import pyarrow
          import pyarrow.parquet
          from pyiceberg.catalog import load_catalog
          print('✓ PyIceberg with PyArrow imported successfully')
          "

      - name: Test wheel size
        run: |
          WHEEL=$(ls wheels/*cp312*${{ matrix.platform_tag }}*.whl | head -1)
          # macOS uses -f%z, Linux uses -c%s
          if [[ "$OSTYPE" == "darwin"* ]]; then
            SIZE=$(stat -f%z "${WHEEL}")
          else
            SIZE=$(stat -c%s "${WHEEL}")
          fi
          SIZE_MB=$((SIZE / 1024 / 1024))
          echo "Wheel size: ${SIZE_MB} MB"
          if [ ${SIZE_MB} -gt 100 ]; then
            echo "⚠ Warning: Wheel is larger than 100MB target"
          else
            echo "✓ Wheel size is acceptable"
          fi
